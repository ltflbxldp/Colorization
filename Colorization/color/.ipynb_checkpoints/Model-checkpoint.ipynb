{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os,keras\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get 5000 images from mountain5000\n",
    "X = []\n",
    "for filename in os.listdir('../mountain5000/'):\n",
    "    X.append(img_to_array(load_img('../mountain5000/'+filename)))\n",
    "#to float array\n",
    "X = np.array(X, dtype=float)\n",
    "# Set up train data\n",
    "Xto1 = 1.0/255*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image generator\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# training data\n",
    "batch_size = 10\n",
    "def dataset(Xto1,batch_size):\n",
    "    for batch in datagen.flow(Xto1, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        Xtr_batch = lab_batch[:,:,:,0]\n",
    "        Ytr_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (Xtr_batch.reshape(Xtr_batch.shape+(1,)), Ytr_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 128)       295040    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 32)      18464     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 128, 128, 2)       578       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 256, 256, 2)       0         \n",
      "=================================================================\n",
      "Total params: 3,892,194\n",
      "Trainable params: 3,892,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 128s 13s/step - loss: 0.0088\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 68s 7s/step - loss: 0.0083\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 69s 7s/step - loss: 0.0089\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.0073\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.0077\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0103\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 71s 7s/step - loss: 0.0079\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0094\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.0071\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0091\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0106\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0077\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0079\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 1493s 149s/step - loss: 0.0095\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 69s 7s/step - loss: 0.0077\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.0072\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0093\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.0086\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0076\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0092\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0081\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.0089\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 65s 6s/step - loss: 0.0086\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0083\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0082\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0073\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0074\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0072\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0083\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0075\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0075\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0079\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0077\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0082\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0076\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0078\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.0102\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 81s 8s/step - loss: 0.0091\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 75s 7s/step - loss: 0.0077\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 70s 7s/step - loss: 0.0078\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 68s 7s/step - loss: 0.0083\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.0091\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0087\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.0087\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 71s 7s/step - loss: 0.0094\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.0067\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0079\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 66s 7s/step - loss: 0.0085\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.0084\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 67s 7s/step - loss: 0.0072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12dfcd0f0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model      \n",
    "model.fit_generator(dataset(Xto1,batch_size), epochs=200, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "t = []\n",
    "keyword='mountain'\n",
    "for i in range(0,100):\n",
    "    t.append(img_to_array(load_img(\"../Mountaintest/{0:s}_{1:04d}.jpg\".format(keyword,i))))\n",
    "t = np.array(t)\n",
    "t= rgb2lab(1.0/255*t)\n",
    "Xts=t[:,:,:,0]\n",
    "Xts = Xts.reshape(Xts.shape+(1,))\n",
    "yts=t[:,:,:,1:]\n",
    "yts=yts/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 227ms/step\n",
      "0.007777458056807518\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "print(model.evaluate(Xts, yts, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/anaconda/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "output = model.predict(Xts)\n",
    "output = output * 128\n",
    "\n",
    "# Output\n",
    "for i in range(len(output)):\n",
    "    color = np.zeros((256, 256, 3))\n",
    "    color[:,:,0] = t[i][:,:,0]\n",
    "    color[:,:,1:] = output[i]\n",
    "    imsave(\"result/col_\"+str(i)+\".png\", lab2rgb(color))\n",
    "    imsave(\"gray/gray_\"+str(i)+\".png\", rgb2gray(lab2rgb(color)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
